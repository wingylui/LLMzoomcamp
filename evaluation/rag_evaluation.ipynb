{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fd394e",
   "metadata": {},
   "source": [
    "## üîç Retrieval System Testing & Evaluation for RAG\n",
    "\n",
    "This notebook is designed to **experiment with multiple retrieval flows** and compare their performance using **retrieval evaluation methods**.  \n",
    "The goal is to identify which retrieval strategy works best for our RAG (Retrieval-Augmented Generation) system.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Retrieval Flows to Test\n",
    "\n",
    "- **Dense Retrieval (Embeddings via Qdrant)**\n",
    "  - Store document embeddings in Qdrant\n",
    "  - Qdrant handles efficient nearest-neighbor search for semantic similarity\n",
    "\n",
    "- **Hybrid Retrieval (BM25 + Qdrant)**\n",
    "  - Combine lexical retrieval (e.g., BM25 from Elasticsearch/Whoosh) with dense retrieval from Qdrant\n",
    "  - Weighted scoring or rank fusion improves precision and recall\n",
    "\n",
    "- **Structured Filtering + Semantic Search**\n",
    "  - Apply metadata/numeric filters (e.g., date, category, calories) directly in Qdrant\n",
    "  - Perform dense retrieval within the filtered subset\n",
    "  - Ensures results are both **relevant** and **contextually constrained**\n",
    "\n",
    "\n",
    "\n",
    "### 2. Retrieval Evaluation Methods\n",
    "\n",
    "- **Hit Rate@K**\n",
    "  - Measures whether at least one relevant document appears in the top-K results  \n",
    "  - Binary (hit or miss), useful for quick assessment  \n",
    "\n",
    "- **Mean Reciprocal Rank (MRR)**\n",
    "  - Evaluates the rank position of the first relevant document  \n",
    "  - Higher score = relevant results appear earlier in the ranking  \n",
    "\n",
    "- **LLM-as-a-Judge**\n",
    "  - Use an LLM to assess whether retrieved documents are relevant to a query  \n",
    "  - Useful when no human-annotated labels exist  \n",
    "  - Can provide **graded relevance scores** instead of binary labels  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab5eeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from api_key import openAI_api_key \n",
    "\n",
    "import json\n",
    "import uuid\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80924525",
   "metadata": {},
   "source": [
    "### LLM prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7260ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful baking assistant. A client has asked the following question:\n",
    "\n",
    "Client question:\n",
    "{user_query}\n",
    "\n",
    "Here are the top {number_of_results} potentially relevant recipes retrieved from the knowledge base:\n",
    "{context_block}\n",
    "\n",
    "Task:\n",
    "- Choose the single most relevant document that best answers the client's question.\n",
    "- Return the recipe from that document only.\n",
    "- Do NOT combine multiple recipes together.\n",
    "- Provide the recipe in natural human-readable format, including all of the following information:\n",
    "    - Recipe name / title\n",
    "    - Difficulty level\n",
    "    - Ingredients list\n",
    "    - Step-by-step instructions\n",
    "    - Total cooking time in minutes\n",
    "    - Calories (kcal)\n",
    "- If none of the documents are relevant, respond: \"I don‚Äôt have a recipe for that.\"\n",
    "\n",
    "Provide your answer as a step-by-step baking recipe.\n",
    "\"\"\"\n",
    "\n",
    "result_template = \"\"\"\n",
    "\"name\"              :   {name},\n",
    "\"difficult\"         :   {difficult},\n",
    "\"total_cooking_min\" :   {total_cooking_min},\n",
    "\"kcal\"              :   {kcal},\n",
    "\"ingredients\"       :   {ingredients},\n",
    "\"steps\"             :   {steps}\n",
    "\"\"\"\n",
    "\n",
    "def format_prompt(prompt_template, question, search_results):\n",
    "    result_number = len(search_results)\n",
    "\n",
    "    formatted_result = []\n",
    "    for result in search_results:\n",
    "        dum = result_template.format(**result).strip()\n",
    "        formatted_result.append(dum)\n",
    "        \n",
    "    # joining the list of text into one block of text (seperated by ;;)\n",
    "    context = \";;\".join(formatted_result)\n",
    "    prompt = prompt_template.format(user_query = question, number_of_results = result_number, context_block = context)\n",
    "\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f75ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_prompt(prompt,  model = \"gpt-5-mini\"):\n",
    "    response = llm_client.chat.completions.create(\n",
    "            model= model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "    result = response.choices[0].message.content # extract the results message out\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4a95e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/baking_cleaned.json\", \"r\") as f:\n",
    "    baking_recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bbe729f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\")\n",
    "llm_client = OpenAI(api_key = openAI_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa6ffaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='baking_recipes_dense')])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85941e",
   "metadata": {},
   "source": [
    "###  Retrieval Flow -- Qdrant (Dense Retrieval)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f2c2a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name = \"baking_recipes_dense\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size = 512,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b5a7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_vector = []\n",
    "for recipe in baking_recipes:\n",
    "    ingred = \";\".join(recipe[\"ingredients\"]) # joining list of text to a block of text\n",
    "    txt = recipe[\"name\"] + \" | \" + recipe[\"difficult\"] + \" | \" + recipe[\"dish_type\"] + \" | \" + recipe[\"description\"] + \" | \" + ingred \n",
    "    point = models.PointStruct(\n",
    "        id = recipe[\"id\"],\n",
    "\n",
    "        vector = models.Document(\n",
    "                    text = txt,\n",
    "                    model = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "                ),\n",
    "\n",
    "        payload = {\n",
    "            \"id\"                :   recipe[\"id\"],\n",
    "            \"name\"              :   recipe[\"name\"],\n",
    "            \"dish_type\"         :   recipe[\"dish_type\"],\n",
    "            \"difficult\"         :   recipe[\"difficult\"],\n",
    "            \"ingredients\"       :   recipe[\"ingredients\"],\n",
    "            \"steps\"             :   recipe[\"steps\"],\n",
    "            \"preparation_min\"   :   recipe['prep_mins'], \n",
    "            \"cooking_min\"       :   recipe['cook_mins'], \n",
    "            \"total_cooking_min\" :   recipe[\"total_mins\"],\n",
    "            \"kcal\"              :   recipe['kcal'], \n",
    "            \"fat\"               :   recipe['fat'], \n",
    "            \"saturated fat\"     :   recipe['saturates'], \n",
    "            \"carbohydrates\"     :   recipe['carbs'], \n",
    "            \"sugars\"            :   recipe['sugars'], \n",
    "            \"fibre\"             :   recipe['fibre'], \n",
    "            \"protein\"           :   recipe['protein'], \n",
    "            \"salt\"              :   recipe['salt'],\n",
    "            \"rating\"           :   recipe[\"rattings\"]\n",
    "        }         \n",
    "    )\n",
    "\n",
    "    points_vector.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "629bac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(\n",
    "    collection_name = \"baking_recipes_dense\",\n",
    "    points = points_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c186beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query):\n",
    "\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name = \"baking_recipes_dense\",\n",
    "        query = models.Document(\n",
    "            text = query,\n",
    "            model = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "        ),\n",
    "        limit = 3,\n",
    "        with_payload = True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321f69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_rag(query, model_name = \"gpt-5-mini\"):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = format_prompt(prompt_template, query, search_results)\n",
    "    answer = llm_prompt(prompt, model= model_name)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee51a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very chocolatey cake\\n\\nDifficulty: Easy\\nTotal cooking time: 60 minutes\\nCalories: 235 kcal\\n\\nIngredients:\\n- 3 eggs\\n- 200 g golden caster sugar\\n- 200 g very soft butter\\n- 200 g self-raising flour\\n- 1 tsp baking powder\\n- 3 tbsp cocoa powder\\n- 100 g chocolate drops (milk, plain, white or a mix)\\n- 300 g soft butter (for icing)\\n- 100 g icing sugar (for icing)\\n- 400 g melted plain chocolate (for icing)\\n\\nStep-by-step instructions:\\n\\n1. Preheat the oven to 180¬∞C (160¬∞C fan) / Gas 4. Grease and line two 20 cm (8 in) round cake tins (or use tins of similar size).\\n\\n2. Crack the eggs into a small bowl, check for any shell fragments and remove them, then tip the eggs into a large mixing bowl.\\n\\n3. Add the 200 g golden caster sugar and 200 g very soft butter to the bowl with the eggs.\\n\\n4. Sift the 200 g self-raising flour, 1 tsp baking powder and 3 tbsp cocoa powder over the egg, sugar and butter mixture.\\n\\n5. Beat everything together until well combined and smooth. You can use a wooden spoon or electric beaters. Once combined, fold in the 100 g chocolate drops.\\n\\n6. Divide the mixture evenly between the two prepared tins, smoothing the tops.\\n\\n7. Bake in the preheated oven for 20‚Äì25 minutes, or until the cakes are risen and a skewer inserted into the centre comes out clean. Remove from the oven and let the cakes cool in the tins for 5 minutes, then turn them out onto a wire rack to cool completely.\\n\\n8. While the cakes cool, make the icing: beat 300 g soft butter with 100 g icing sugar until smooth, then fold in the 400 g melted plain chocolate until you have an even chocolate buttercream.\\n\\n9. When the cakes are completely cool, spread a layer of the chocolate icing over one cake, sandwich the second cake on top, then spread the remaining icing over the top (and sides, if you like). Dust lightly with a little icing sugar if desired.\\n\\n10. Slice and serve. Store any leftovers in an airtight container.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I want to make a chocolate cake\"\n",
    "ans = dense_rag(query)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcdc761",
   "metadata": {},
   "source": [
    "###  Retrieval Flow -- Qdrant (hybrid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bba65705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name= \"baking_recipes_description\",\n",
    "    vectors_config={\n",
    "        \"jina-v2\" : models.VectorParams(\n",
    "            size = 512, #embedding dimensionality\n",
    "            distance = models.Distance.COSINE,\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config = {\n",
    "        \"bm25\" : models.SparseVectorParams(\n",
    "            modifier = models.Modifier.IDF\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c01c9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_vector = []\n",
    "for recipe in baking_recipes:\n",
    "    ingred = \";\".join(recipe[\"ingredients\"]) # joining list of text to a block of text\n",
    "    txt = recipe[\"name\"] + \" | \" + recipe[\"difficult\"] + \" | \" + recipe[\"dish_type\"] + \" | \" + recipe[\"description\"] + \" | \" + ingred \n",
    "    point = models.PointStruct(\n",
    "        id = recipe[\"id\"],\n",
    "        \n",
    "        vector = {\n",
    "            \"jina-v2\": models.Document(\n",
    "                    text = txt,\n",
    "                    model =\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "            \"bm25\": models.Document(\n",
    "                    text = txt, \n",
    "                    model =\"Qdrant/bm25\",\n",
    "                )\n",
    "        },\n",
    "\n",
    "        payload = {\n",
    "            \"id\"                :   recipe[\"id\"],\n",
    "            \"name\"              :   recipe[\"name\"],\n",
    "            \"dish_type\"         :   recipe[\"dish_type\"],\n",
    "            \"difficult\"         :   recipe[\"difficult\"],\n",
    "            \"ingredients\"       :   recipe[\"ingredients\"],\n",
    "            \"steps\"             :   recipe[\"steps\"],\n",
    "            \"preparation_min\"   :   recipe['prep_mins'], \n",
    "            \"cooking_min\"       :   recipe['cook_mins'], \n",
    "            \"total_cooking_min\" :   recipe[\"total_mins\"],\n",
    "            \"kcal\"              :   recipe['kcal'], \n",
    "            \"fat\"               :   recipe['fat'], \n",
    "            \"saturated fat\"     :   recipe['saturates'], \n",
    "            \"carbohydrates\"     :   recipe['carbs'], \n",
    "            \"sugars\"            :   recipe['sugars'], \n",
    "            \"fibre\"             :   recipe['fibre'], \n",
    "            \"protein\"           :   recipe['protein'], \n",
    "            \"salt\"              :   recipe['salt'],\n",
    "            \"rating\"           :   recipe[\"rattings\"]\n",
    "        }         \n",
    "    )\n",
    "\n",
    "    points_vector.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f83dabb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(\n",
    "    collection_name=\"baking_recipes_description\",\n",
    "    points = points_vector \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66a34d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_description_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = qd_client.query_points(\n",
    "        collection_name=\"baking_recipes_description\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-v2\",\n",
    "                limit=(3 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(3 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    search_results = []\n",
    "    \n",
    "    for point in results.points:\n",
    "        search_results.append(point.payload)\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c3ccedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_description_rag(query, model_name = \"gpt-5-mini\"):\n",
    "    search_results = rrf_description_search(query)\n",
    "    prompt = format_prompt(prompt_template, query, search_results)\n",
    "    answer = llm_prompt(prompt, model= model_name)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56bc0194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pizza rolls\\nDifficulty: Easy\\nTotal cooking time: 30 minutes\\nCalories: 275 kcal (per roll, as listed)\\n\\nIngredients\\n- 6 crusty bread rolls\\n- 2 tbsp tomato pur√©e\\n- 6 slices ham\\n- 3 tomatoes, sliced\\n- 2 balls mozzarella, sliced (we used Sainsbury's Basics)\\n- 2 tsp dried oregano\\n- 6 black olives (optional)\\n\\nStep-by-step instructions\\n1. Heat the oven to 180¬∞C / 160¬∞C fan / Gas 4.\\n2. Cut the tops off the rolls and scoop out the insides to make little hollow bread cups.\\n3. Spread the inside of each roll with tomato pur√©e.\\n4. Fill each roll with a slice of ham, a few slices of tomato, then top with slices of mozzarella.\\n5. Scatter dried oregano over each filled roll and top each one with an olive if using.\\n6. Place the filled rolls on a baking tray and bake for about 15 minutes, until the rolls are crusty brown and the cheese is bubbling.\\n7. Leave to rest for 1 minute, then serve hot (they go nicely with a simple side salad).\\n\\nNote: To serve a larger group of kids, double all ingredients (to make 12 rolls) and bake on two trays or in batches.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = hybrid_description_rag(\"Crowd-friendly pizza roll recipe that can be doubled to feed a group of kids‚Äîeasy to make?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5dc70",
   "metadata": {},
   "source": [
    "###  Retrieval Flow -- Qdrant (hybrid search + filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "203b7ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name= \"baking_recipes_hybrid\",\n",
    "    vectors_config={\n",
    "        \"jina-v2\" : models.VectorParams(\n",
    "            size = 512, #embedding dimensionality\n",
    "            distance = models.Distance.COSINE,\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config = {\n",
    "        \"bm25\" : models.SparseVectorParams(\n",
    "            modifier = models.Modifier.IDF\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca12bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_setup(js : json, section, txt : str, counter = \"\"):\n",
    "    point = models.PointStruct(\n",
    "        id = str(uuid.uuid4()),\n",
    "        vector = {\n",
    "            \"jina-v2\": models.Document(\n",
    "                    text = txt,\n",
    "                    model =\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "            \"bm25\": models.Document(\n",
    "                    text = txt, \n",
    "                    model =\"Qdrant/bm25\",\n",
    "                )\n",
    "        },\n",
    "        payload = {\n",
    "            \"id\"                :   js[\"id\"],\n",
    "            \"section\"           :   section,\n",
    "            \"name\"              :   js[\"name\"],\n",
    "            \"dish_type\"         :   js[\"dish_type\"],\n",
    "            \"difficult\"         :   js[\"difficult\"],\n",
    "            \"ingredients\"       :   js[\"ingredients\"],\n",
    "            \"steps\"             :   js[\"steps\"],\n",
    "            \"preparation_min\"   :   js['prep_mins'], \n",
    "            \"cooking_min\"       :   js['cook_mins'], \n",
    "            \"total_cooking_min\" :   js[\"total_mins\"],\n",
    "            \"kcal\"              :   js['kcal'], \n",
    "            \"fat\"               :   js['fat'], \n",
    "            \"saturated fat\"     :   js['saturates'], \n",
    "            \"carbohydrates\"     :   js['carbs'], \n",
    "            \"sugars\"            :   js['sugars'], \n",
    "            \"fibre\"             :   js['fibre'], \n",
    "            \"protein\"           :   js['protein'], \n",
    "            \"salt\"              :   js['salt'],\n",
    "            \"rating\"           :   js[\"rattings\"]\n",
    "        }         \n",
    "    )\n",
    "\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50fa6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_points = []\n",
    "\n",
    "for i, recipe in enumerate(baking_recipes):\n",
    "    # join name, description, dish type and difficult into a section\n",
    "    description_txt = recipe[\"name\"] + \" | \" + recipe[\"difficult\"] + \" | \" + recipe[\"dish_type\"] + \" | \" + recipe[\"description\"]\n",
    "    des_point = point_setup(recipe, \"description\", description_txt)\n",
    "    qd_points.append(des_point)\n",
    "\n",
    "\n",
    "    # join ingredients into a section\n",
    "    ingredient_txt = \"; \".join(recipe[\"ingredients\"])\n",
    "    ing_point = point_setup(recipe, \"ingredients\", ingredient_txt)\n",
    "    qd_points.append(ing_point)\n",
    "\n",
    "\n",
    "    # chunked steps into different section\n",
    "    counter = 1\n",
    "    for each_step in recipe[\"steps\"]:\n",
    "        step_point = point_setup(recipe, \"steps\", each_step, str(counter))\n",
    "        qd_points.append(step_point)\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a809ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "\n",
    "for i in range(0, len(qd_points), BATCH_SIZE):\n",
    "    batch = qd_points[i:i + BATCH_SIZE]\n",
    "    qd_client.upsert(\n",
    "        collection_name=\"baking_recipes_hybrid\",\n",
    "        points=batch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b7b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_search(query: str, filters, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = qd_client.query_points(\n",
    "        collection_name=\"baking_recipes_hybrid\",\n",
    "        \n",
    "        query_filter = models.Filter(\n",
    "            must = filters\n",
    "        ),\n",
    "\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-v2\",\n",
    "                limit=(2 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(2 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4ecf866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_classifier(query, model = \"gpt-5-mini\"):\n",
    "    \"\"\"\n",
    "    this block is using LLM to classify which section for this question is below to\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Given a user question, output JSON with:\n",
    "\n",
    "    1. \"relevant_sections\": choose only from:\n",
    "    [description, ingredients, steps, preparation_min, cooking_min, total_cooking_min, kcal, fat, saturated_fat, carbohydrates, sugars, fibre, protein, salt, rating]\n",
    "\n",
    "    Rules:\n",
    "    - description ‚Üí dish/general info\n",
    "    - ingredients ‚Üí if components mentioned\n",
    "    - steps ‚Üí only if instructions asked\n",
    "    - numeric fields ‚Üí only if numbers mentioned (time, calories, etc.)\n",
    "\n",
    "    2. \"filter\": list numeric filters as \"field operator value\"\n",
    "    - Convert hours ‚Üí minutes\n",
    "    - For ranges, keep the larger value\n",
    "    - rating must be numeric\n",
    "    - use \"lte\" = ‚â§, \"gte\" = ‚â•\n",
    "\n",
    "    Output format (no code block):\n",
    "    {{\n",
    "    \"relevant_sections\": [...],\n",
    "    \"filter\": {{...}}\n",
    "    }}\n",
    "\n",
    "    Example:\n",
    "    Q: Easy white bread rolls ready in 60 minutes with saturated fat < 1g?\n",
    "    A: {{\n",
    "    \"relevant_sections\": [\"description\",\"total_cooking_min\",\"saturated_fat\"],\n",
    "    \"filter\": {{\"total_cooking_min\":\"lte,60\",\"saturated_fat\":\"lte,1\"}}\n",
    "    }}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = prompt_template.format(question = query).strip()\n",
    "    response = llm_prompt(prompt, model= model)\n",
    "    result_js = json.loads(response)\n",
    "\n",
    "    return result_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aac12167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_search(query, classifier):\n",
    "    seen_ids = set()\n",
    "    search_results = []\n",
    "\n",
    "    for section in classifier[\"relevant_sections\"]:\n",
    "        qd_filter = []\n",
    "        # set up relevant section for text search\n",
    "        section_filter = models.FieldCondition(\n",
    "                            key = \"section\",\n",
    "                            match = models.MatchValue(value = section)\n",
    "                        )\n",
    "        qd_filter.append(section_filter)\n",
    "        # filter section and then do a vector search\n",
    "        results = rrf_search(query = query, filters = qd_filter)\n",
    "\n",
    "        # combining the rrf_search with the previous rrf_search\n",
    "        for point in results:\n",
    "            # if the point is not appear before then will put in to search results list\n",
    "            if point.payload[\"id\"] not in seen_ids:\n",
    "                search_results.append(point)\n",
    "                seen_ids.add(point.payload[\"id\"])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # formatting results\n",
    "    final_results = []\n",
    "    for point in search_results:\n",
    "        final_results.append(point.payload)\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c55d94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_numeric_search(query, classifier):\n",
    "    \n",
    "    seen_ids = set()\n",
    "    search_results = []\n",
    "\n",
    "    # first : hybrid (text) search\n",
    "    for section in classifier[\"relevant_sections\"]:\n",
    "        qd_filter = []\n",
    "        # set up relevant section for text search\n",
    "        section_filter = models.FieldCondition(\n",
    "                        key = \"section\",\n",
    "                        match = models.MatchValue(value = section)\n",
    "                    )\n",
    "        qd_filter.append(section_filter)\n",
    "\n",
    "        # second : numeric search \n",
    "        for numeric_filter in classifier[\"filter\"].keys():\n",
    "            filter_val = classifier[\"filter\"][numeric_filter].split(',')\n",
    "            # if the value is >= xx then is gt \n",
    "            if filter_val[0] == \"gte\":\n",
    "                num_filter = models.FieldCondition(\n",
    "                                key = numeric_filter,\n",
    "                                range = models.Range(gte = filter_val[1])\n",
    "                            )\n",
    "                qd_filter.append(num_filter)\n",
    "            # if the value is <= xx then is lte \n",
    "            elif filter_val[0] == \"lte\":\n",
    "                num_filter = models.FieldCondition(\n",
    "                                key = numeric_filter,\n",
    "                                range = models.Range(lte = filter_val[1])\n",
    "                            )\n",
    "                qd_filter.append(num_filter)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # filter section and then do a vector search\n",
    "        results = rrf_search(query = query, filters = qd_filter)\n",
    "        \n",
    "        # combining the rrf_search with the previous rrf_search\n",
    "        for point in results:\n",
    "            # if the point is not appear before then will put in to search results list\n",
    "            if point.payload[\"id\"] not in seen_ids:\n",
    "                search_results.append(point)\n",
    "                seen_ids.add(point.payload[\"id\"])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # formatting results\n",
    "    final_results = []\n",
    "    for point in search_results:\n",
    "        final_results.append(point.payload)\n",
    "                \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18a946e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, model_name = \"gpt-5-mini\"):\n",
    "    \"\"\"\n",
    "    identifying what kinda of question is it and then filtering it with text or numerical filtering\n",
    "    \"\"\"\n",
    "    unable_to_run = []\n",
    "    classifier = question_classifier(query, model = model_name)\n",
    "\n",
    "    try:\n",
    "        # removing section that need numeric filter\n",
    "        for numeric_filter in classifier[\"filter\"].keys():\n",
    "            classifier[\"relevant_sections\"].remove(numeric_filter)\n",
    "\n",
    "        if len(classifier[\"filter\"].keys()) == 0:\n",
    "            search_results = text_search(query, classifier)\n",
    "        else:\n",
    "            search_results = text_numeric_search(query, classifier)\n",
    "    except:\n",
    "        print(f\"unexpected error: {query}\")\n",
    "        unable_to_run.append(query)\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "950d570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_rag(query, model_name = \"gpt-5-mini\"):\n",
    "    \n",
    "    search_results = hybrid_search(query, model_name = model_name)\n",
    "    # formatting prompt and ask llm to give the correct results\n",
    "    prompt = format_prompt(prompt_template, query, search_results)\n",
    "    answer = llm_prompt(prompt, model= model_name)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5743b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe: Pizza rolls\\nDifficulty: Easy\\nTotal cooking time: 30 minutes\\nCalories: 275 kcal\\n\\nIngredients\\n- 6 crusty bread rolls\\n- 2 tbsp tomato pur√©e\\n- 6 slices ham\\n- 3 tomatoes, sliced\\n- 2 balls mozzarella, sliced\\n- 2 tsp dried oregano\\n- 6 black olives (optional)\\n\\nStep-by-step instructions\\n1. Heat the oven to 180¬∞C / 160¬∞C fan / Gas 4.\\n2. Cut the tops off the rolls and scoop out the insides to make a hollow cavity in each roll.\\n3. Spread each hollowed roll with tomato pur√©e.\\n4. Fill each roll with a slice of ham, a few slices of tomato, and top with slices of mozzarella.\\n5. Scatter each filled roll with dried oregano. Top each roll with a black olive if using.\\n6. Place the filled rolls on a baking tray and bake for 15 minutes, until the rolls are crusty brown and the cheese is bubbling.\\n7. Leave to rest for 1 minute, then serve hot (served well with a side salad).\\n\\nEnjoy your pizza rolls!'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = hybrid_rag(\"Crowd-friendly pizza roll recipe that can be doubled to feed a group of kids‚Äîeasy to make?\")\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae1929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ploughman‚Äôs rolls\\nDifficulty: Easy\\nTotal cooking time: 62 minutes\\nCalories: 250 kcal (per roll)\\n\\nIngredients\\n- 1 tbsp celery seeds, plus a few extra\\n- 500g pack bread dough\\n- 200ml milk, plus a splash to glaze\\n- 100g extra-mature cheddar, grated\\n- 85g English Brie or camembert, diced\\n- 1 small apple, cored and diced into small chunks\\n- 2 spring onions, finely chopped\\n- 1 tbsp poppy seed\\n- Plain flour, for dusting\\n- Pickle, to serve\\n\\nStep-by-step instructions\\n1. Stir 1 tbsp celery seeds into the bread dough mix.\\n2. Pour 200ml milk into a jug and make up to 325ml with water. Warm to hand temperature (you can do this briefly in the microwave). Add the warmed liquid to the bread mix and bring together following the pack instructions. Leave the dough to rise in a warm place until about doubled in size.\\n3. Meanwhile, mix together 85g of the grated cheddar, the diced Brie or camembert, diced apple and finely chopped spring onions. Season lightly.\\n4. Once the dough has risen, divide it into 8 even pieces.\\n5. On a floured surface, roll each piece into a roughly 10cm-wide circle (about the thickness of a naan). Spoon one-eighth of the cheesy apple mixture into the centre of each circle.\\n6. Gather the edges of the dough up around the filling and pinch together to seal firmly so the filling won‚Äôt burst out while baking. Turn each roll over so the pinched seam is underneath and press to shape if needed. Place the rolls on floured baking sheets, spaced a little apart. Cover with oiled cling film and set aside in a warm place for about 30 minutes to prove.\\n7. Preheat the oven to 200¬∞C / 180¬∞C fan / gas 6.\\n8. Brush the rolls with a splash of milk. Scatter poppy seeds over the tops, add a pinch more celery seeds if you like, and sprinkle with the remaining grated cheddar.\\n9. Bake the rolls for 20‚Äì22 minutes, until golden and cooked through.\\n10. Remove from the oven and cool slightly. Serve warm or cold with pickle.\\n\\nEnjoy your Ploughman‚Äôs-style cheese rolls (about 250 kcal per roll).'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_ = hybrid_rag(\"Lunch idea: Ploughman's-style cheese rolls with apple and poppy seeds, around 250 kcal per roll?\")\n",
    "ans_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce479c",
   "metadata": {},
   "source": [
    "## Retrieval evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "338565f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16a94310-cea8-435f-90e8-10f8b02b7bfe</td>\n",
       "      <td>Easy white bread rolls for sandwiches or burge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16a94310-cea8-435f-90e8-10f8b02b7bfe</td>\n",
       "      <td>Simple homemade rolls using strong white bread...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  16a94310-cea8-435f-90e8-10f8b02b7bfe   \n",
       "1  16a94310-cea8-435f-90e8-10f8b02b7bfe   \n",
       "\n",
       "                                           questions  \n",
       "0  Easy white bread rolls for sandwiches or burge...  \n",
       "1  Simple homemade rolls using strong white bread...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_df = pd.read_csv(\"../data/ground_truth_retrieval.csv\", usecols=['id', 'questions'])\n",
    "eva_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c92eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_js = eva_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecdae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52fad245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6616e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_func(ground_truth, search_function, method):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        try:\n",
    "            results = search_function(q)\n",
    "        except:\n",
    "            relevance = [False, False, False, False, False]\n",
    "\n",
    "        if method == \"vector_search\":\n",
    "            relevance = [d['id'] == doc_id for d in results]\n",
    "        elif method == \"hybrid_search\":\n",
    "            relevance = [d['id'] == doc_id for d in results]\n",
    "        else:\n",
    "            print(\"wrong method\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        relevance_total.append(relevance)\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbec13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3070/3070 [01:37<00:00, 31.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9276872964169381, 'mrr': 0.8225298588490784}"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_func(eva_js, lambda x: vector_search(x[\"questions\"]), \"vector_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b020b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3070/3070 [01:35<00:00, 32.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9716612377850163, 'mrr': 0.8546525515743764}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_func(eva_js, lambda x: rrf_description_search(x[\"questions\"]), \"vector_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ab5e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 142/150 [20:27<01:21, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unexpected error: Top-rated (5-star) aubergine and tomato baklava with dates and honey ‚Äî what are the prep and cooking times?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [21:30<00:00,  8.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8866666666666667, 'mrr': 0.7378412698412699}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_func(eva_js, lambda x: hybrid_search(x[\"questions\"]), \"hybrid_search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ac948",
   "metadata": {},
   "source": [
    "## LLM evaluation \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b93fd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMeva_prompt_template = \"\"\"\n",
    "You are an evaluator for a RAG system.\n",
    "Classify the generated answer‚Äôs relevance to the question as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Input:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: {llm_ans}\n",
    "\n",
    "Output (JSON, no code block):\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Brief reason for classification]\"\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f006c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = eva_df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3feb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_evaulation(df, model):\n",
    "    evaluate_results = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        question = row[\"questions\"]\n",
    "        ans_llm = hybrid_description_rag(question, model_name = model)\n",
    "        # reformat the prompt\n",
    "        prompt = LLMeva_prompt_template.format(question= question, llm_ans = ans_llm)\n",
    "\n",
    "        # LLM-as-a-judge\n",
    "        response = llm_prompt(prompt, model = model)\n",
    "        evaluate = json.loads(response)\n",
    "\n",
    "        # formatting for data storage\n",
    "        result_js = {\n",
    "            \"id\"            :   row[\"id\"],\n",
    "            \"question\"      :   question,\n",
    "            \"llm_answer\"    :   ans_llm,\n",
    "            \"relevance\"     :   evaluate[\"Relevance\"],\n",
    "            \"explanation\"   :   evaluate[\"Explanation\"]\n",
    "        }\n",
    "\n",
    "        evaluate_results.append(result_js)\n",
    "\n",
    "    return evaluate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7e232be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [1:11:02, 21.31s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluation_5mini = llm_evaulation(sampled_df, model = \"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a39152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88cdc06c-19a2-4c4a-b7bd-8c7600a25552</td>\n",
       "      <td>Do you have a chocolate and vanilla celebratio...</td>\n",
       "      <td>Chocolate &amp; vanilla celebration cake\\nDifficul...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The answer provides a full chocolate-and-vanil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72a6dbdd-e1f7-47a5-b2a7-e46259ae7cdf</td>\n",
       "      <td>Family-friendly rhubarb crumble dessert, rough...</td>\n",
       "      <td>Rhubarb crumble\\nDifficulty: Easy\\nTotal cooki...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The answer provides a complete family-friendly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  88cdc06c-19a2-4c4a-b7bd-8c7600a25552   \n",
       "1  72a6dbdd-e1f7-47a5-b2a7-e46259ae7cdf   \n",
       "\n",
       "                                            question  \\\n",
       "0  Do you have a chocolate and vanilla celebratio...   \n",
       "1  Family-friendly rhubarb crumble dessert, rough...   \n",
       "\n",
       "                                          llm_answer relevance  \\\n",
       "0  Chocolate & vanilla celebration cake\\nDifficul...  RELEVANT   \n",
       "1  Rhubarb crumble\\nDifficulty: Easy\\nTotal cooki...  RELEVANT   \n",
       "\n",
       "                                         explanation  \n",
       "0  The answer provides a full chocolate-and-vanil...  \n",
       "1  The answer provides a complete family-friendly...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_5mini_df = pd.DataFrame(evaluation_5mini)\n",
    "eva_5mini_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "961a8d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           156\n",
       "PARTLY_RELEVANT     44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_5mini_df[\"relevance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10b78cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_5mini_df.to_csv(\"../data/GPT_5mini_evaluation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "660ad3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [1:06:15, 19.88s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluation_5nano = llm_evaulation(sampled_df, model = \"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b298378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88cdc06c-19a2-4c4a-b7bd-8c7600a25552</td>\n",
       "      <td>Do you have a chocolate and vanilla celebratio...</td>\n",
       "      <td>Chocolate &amp; vanilla celebration cake\\nDifficul...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The answer provides a complete recipe for a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72a6dbdd-e1f7-47a5-b2a7-e46259ae7cdf</td>\n",
       "      <td>Family-friendly rhubarb crumble dessert, rough...</td>\n",
       "      <td>Rhubarb crumble\\nDifficulty: Easy\\nTotal cooki...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The answer provides a full rhubarb crumble rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  88cdc06c-19a2-4c4a-b7bd-8c7600a25552   \n",
       "1  72a6dbdd-e1f7-47a5-b2a7-e46259ae7cdf   \n",
       "\n",
       "                                            question  \\\n",
       "0  Do you have a chocolate and vanilla celebratio...   \n",
       "1  Family-friendly rhubarb crumble dessert, rough...   \n",
       "\n",
       "                                          llm_answer relevance  \\\n",
       "0  Chocolate & vanilla celebration cake\\nDifficul...  RELEVANT   \n",
       "1  Rhubarb crumble\\nDifficulty: Easy\\nTotal cooki...  RELEVANT   \n",
       "\n",
       "                                         explanation  \n",
       "0  The answer provides a complete recipe for a ch...  \n",
       "1  The answer provides a full rhubarb crumble rec...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_5nano_df = pd.DataFrame(evaluation_5nano)\n",
    "eva_5nano_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be5bf4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           165\n",
       "PARTLY_RELEVANT     33\n",
       "NON_RELEVANT         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_5nano_df[\"relevance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81a6b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_5nano_df.to_csv(\"../data/GPT_5nano_evaluation.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMZoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
