# LLMzoomcamp
# ğŸ° Baking Assistant â€” Recipe Retrieval and Recommendation System

A **Retrieval-Augmented Generation (RAG)** application that helps users discover and generate baking recipes using natural language.  
The project integrates **semantic search**, **structured filtering**, and **LLM-based evaluation** to identify the most effective retrieval pipeline for recipe search and generation.

---

## ğŸš€ Project Overview

This project demonstrates an end-to-end **RAG pipeline** for structured recipe data.  
It combines **Qdrant** for vector-based retrieval, **Postgres** for metadata storage, **Streamlit** for interaction, and **Grafana** for monitoring â€” creating a complete experimentation and evaluation environment.

### Key Features
- ğŸ” **Semantic & Hybrid Retrieval** using Qdrant + BM25  
- ğŸ§  **LLM Evaluation** for assessing retrieval quality and relevance  
- ğŸ“Š **Performance Monitoring** via Grafana  
- ğŸ’¬ **Interactive Streamlit Chat Interface** for recipe search and feedback collection  

---

## ğŸ§± System Architecture


---

## ğŸ¥ BakeBuddy Demo

Hereâ€™s a short demo of the BakeBuddy Streamlit app in action:


[![VideoDemo](img/video_demo.gif)](https://www.youtube.com/watch?v=b7oyp3wkDCAs)

---

## âš™ï¸ Installation and Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/wingylui/LLMzoomcamp.git
cd baking-assistant
```

### 2ï¸âƒ£ Environment Variables
Create a `.env` file:
```env
POSTGRES_DB=baking_assistant
POSTGRES_USER=admin
POSTGRES_PASSWORD=password
POSTGRES_PORT=5433
QDRANT_PORT=6333
```

### 3ï¸âƒ£ Build and Run with Docker Compose
```bash
docker compose up --build
```
This launches the full stack:

| Service | Description | URL |
|---------|-------------|-----|
| ğŸ§ Streamlit | Recipe search interface | [http://localhost:8501](http://localhost:8501) |
| ğŸ—„ï¸ Postgres | Structured metadata storage | localhost:5433 |
| ğŸ§  Qdrant | Vector similarity search | [http://localhost:6333](http://localhost:6333) |
| ğŸ“Š Grafana | Metrics and monitoring | [http://localhost:3000](http://localhost:3000) |

---

## ğŸ“‚ Workflow Summary

### 1. Data Preparation
The recipe dataset was cleaned and normalized into a structured JSON format.  
Each record contains descriptive text fields (name, description, ingredients, etc.), numeric metadata (e.g., calories, time), and categorical features (e.g., difficulty, dish type).  

This structure supports both **semantic embedding** for dense retrieval and **metadata filtering** for structured queries.  
The processed dataset is stored in Postgres for efficient querying and vectorization.

---

### 2. Ground Truth Question Generation
To evaluate retrieval effectiveness, a synthetic *ground truth question set* was generated automatically using an LLM.  
For each recipe, the model produced several natural, human-like search questions that reflect realistic user intent â€” such as ingredient-based searches, cooking duration, or style preferences.

This questionâ€“recipe mapping became the benchmark for retrieval evaluation, allowing the system to test whether relevant recipes are correctly retrieved and ranked.

---

### 3. Retrieval Strategies
The project tests three retrieval modes:

1. **Dense Retrieval (Qdrant only)** â€“ semantic similarity using embeddings  
2. **Hybrid Retrieval (BM25 + Dense)** â€“ combines lexical and dense scores  
3. **Hybrid + Metadata Filter** â€“ adds structured constraints (e.g., calories or difficulty)

Each method is evaluated to measure accuracy, precision, and retrieval ranking.

---

### 4. Retrieval Evaluation
Multiple evaluation methods were applied:

- **Hit Rate@K** â€“ measures whether a relevant document appears within top results  
- **Mean Reciprocal Rank (MRR)** â€“ evaluates how early relevant results appear  
- **LLM-as-a-Judge** â€“ GPT model provides qualitative relevance grading  

#### Results Summary

| Retrieval Method | Hit Rate | MRR |
|-----------------|----------|-----|
| Dense | 0.928 | 0.823 |
| Hybrid | 0.972 | 0.855 |
| Hybrid + Filter | 0.887 | 0.738 |

#### LLM Relevance Evaluation

| Model | RELEVANT | PARTLY_RELEVANT | NON_RELEVANT |
|-------|----------|----------------|---------------|
| 5-nano | 156 | 44 | 0 |
| 5-mini | 165 | 33 | 2 |

---

## ğŸ§ Streamlit App
The **Streamlit interface** provides a user-friendly chat experience for recipe discovery.  
Users can:  
- Ask baking-related questions in natural language  
- Receive tailored recipe suggestions  
- Provide quick feedback (â€œhelpfulâ€, â€œnot helpfulâ€, â€œneutralâ€), which is logged for model improvement  (10% chances)

![Streamlit App](img/chatbox_page.png)

---

## ğŸ“Š Monitoring with Grafana
**Grafana** tracks and visualizes:  
- Query response latency  
- Retrieval method comparison  
- User feedback trends  
- LLM evaluation scores  

This supports transparent performance monitoring and model tuning over time.

![Grafana Dashboard](img/minitor_dashboard.png)

---

## ğŸ§© Folder Structure
```
baking-assistant/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ ingestion.py
â”‚ â”œâ”€â”€ interface.py   # Streamlit / user interface
â”‚ â”œâ”€â”€ minitor.py
â”‚ â””â”€â”€ rag.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ baking_cleaned.json
â”‚ â”œâ”€â”€ baking.json
â”‚ â”œâ”€â”€ GPT_5mini_evaluation.csv
â”‚ â”œâ”€â”€ GPT_5nano_evaluation.csv
â”‚ â””â”€â”€ ground_truth_retrieval.csv
â”œâ”€â”€ data_processing/
â”‚ â”œâ”€â”€ data_cleaning.ipynb
â”‚ â””â”€â”€ evaluation_data_gen.ipynb
â”œâ”€â”€ DB/
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ evaluation/
â”‚ â””â”€â”€ rag_evaluation.ipynb
â”œâ”€â”€ grafana/
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ minitor_dashboard.json
â”œâ”€â”€ img/
â”œâ”€â”€ Pipfile.lock
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```


---
## ğŸ§ª Future Work
- Add **active learning loop** to retrain retrieval embeddings from user feedback  
- Incorporate **re-ranking models** for hybrid search optimization  


